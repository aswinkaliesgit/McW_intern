{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4By4M9brP-s9",
        "outputId": "4b35a913-7598-49ac-9b4d-de9554eef4d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElgwXK7GQqK_",
        "outputId": "3c639689-016d-457c-df2e-1e94bcb91cbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-8uz4e1_v\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-8uz4e1_v\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 0d2ab99cccbbc682722e708515fe9c4cfc50185a\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4716 sha256=9418a56cbb707684c4eef2d81481e71c3366275f077bbbd092e918f3b23116f4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ptur0szn/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8jlLnV6Qy5_",
        "outputId": "6c707ce1-73af-44eb-88f1-c65da876d88b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UV2LPFAimaJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCoSk7w1Q9Lb",
        "outputId": "3bb7213a-b16d-4d09-e9d7-dec10f0980c7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaZqmjI8mRos",
        "outputId": "834f566e-421d-45d2-97c4-03f86f00669d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-4q2xrd_a\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-4q2xrd_a\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 0d2ab99cccbbc682722e708515fe9c4cfc50185a\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4716 sha256=d392aa0948dc9dfbe5aa8d02f3f3ad48bfe0144c7c1184691152d7f2c458494f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1_vvq383/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNv7ILqCmbcz",
        "outputId": "682e3a80-5669-48e7-dc3d-5897aa550b9b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "\n",
        "#include<iostream>\n",
        "#include<vector>\n",
        "#define size 1000000\n",
        "__global__ void VectorAdd(int* a,int *b,int *c,int N)\n",
        "{\n",
        "    int t_x= (blockIdx.x*blockDim.x)+ threadIdx.x;\n",
        "    if(t_x<N) c[t_x]=a[t_x]+b[t_x];\n",
        "}\n",
        "void reference(std::vector<int>& a, std::vector<int>& b,std::vector<int>& c) {\n",
        "           cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "cudaEventRecord(start);\n",
        "    for (int i = 0; i <size; i++)\n",
        "     c[i]= a[i] + b[i];\n",
        "            cudaEventRecord(stop);\n",
        "         cudaEventSynchronize(stop);\n",
        "    float elapsed_time_ms;\n",
        "    cudaEventElapsedTime(&elapsed_time_ms, start, stop);\n",
        "           std::cout<<\"CPU EXECUTION:\"<<elapsed_time_ms<<\"\\n\";\n",
        "}\n",
        "int main()\n",
        "{\n",
        "     int N=size;\n",
        "     size_t bytes=sizeof(int)*N;\n",
        "\n",
        "    std::vector<int> a;\n",
        "    a.reserve(N);\n",
        "    std::vector<int> b;\n",
        "    b.reserve(N);\n",
        "    std::vector<int> c;\n",
        "    c.reserve(N);\n",
        "\n",
        "\n",
        "    for(int i=0;i<N;i++)\n",
        "    {\n",
        "        a.push_back(rand()%100);\n",
        "        b.push_back(rand()%100);\n",
        "    }\n",
        "\n",
        "    int *d_a,*d_b,*d_c;\n",
        "\n",
        "    cudaMalloc(&d_a,bytes);\n",
        "    cudaMalloc(&d_b,bytes);\n",
        "    cudaMalloc(&d_c,bytes);\n",
        "\n",
        "    cudaMemcpy(d_a,a.data(),bytes,cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b,b.data(),bytes,cudaMemcpyHostToDevice);\n",
        "\n",
        "    int blocksize = 1<<10;\n",
        "    int gridsize = (N+blocksize-1)/blocksize;\n",
        "       cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "cudaEventRecord(start);\n",
        "    VectorAdd<<<gridsize,blocksize>>>(d_a,d_b,d_c,N);\n",
        " cudaEventRecord(stop);\n",
        "         cudaEventSynchronize(stop);\n",
        "    float elapsed_time_ms;\n",
        "    cudaEventElapsedTime(&elapsed_time_ms, start, stop);\n",
        "\n",
        "    cudaMemcpy(c.data(),d_c,bytes,cudaMemcpyDeviceToHost);\n",
        "      for(int i=0;i<50;i++)\n",
        "     {\n",
        "         std::cout<<c[i]<<\"\\t\";\n",
        "     }\n",
        "     std::cout<<\"\\n\";\n",
        "     std::cout<<\"GPU_EXECUTION:\"<<elapsed_time_ms<<\"\\n\";\n",
        "     std::cout<<\"\\n\";\n",
        "     reference(a,b,c);\n",
        "    std::cout<<\"COMPLETED\";\n",
        "    return 0;\n",
        "\n",
        "\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6himHk9mdrw",
        "outputId": "01586840-faef-4851-c382-2bfd56ea27d1"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "169\t92\t128\t178\t70\t89\t149\t89\t66\t108\t79\t96\t112\t85\t102\t31\t80\t136\t149\t53\t102\t40\t121\t122\t85\t39\t171\t129\t132\t177\t30\t111\t41\t75\t70\t119\t127\t81\t98\t93\t95\t154\t172\t54\t153\t92\t144\t51\t112\t133\t\n",
            "GPU_EXECUTION:0.203808\n",
            "\n",
            "CPU EXECUTION:7.39229\n",
            "COMPLETED\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFGL6wpWzd1A",
        "outputId": "b62e358b-ccda-4dd5-c315-a68096350b23"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jan 14 17:19:13 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    }
  ]
}