{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jygZwnkDEHvI",
        "outputId": "3e7cb4d2-ead2-45b7-c449-b76576f4edf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-lspladwp\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-lspladwp\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 0d2ab99cccbbc682722e708515fe9c4cfc50185a\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "The nvcc_plugin extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc_plugin\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
        "\n",
        "%load_ext nvcc_plugin"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W0fQOlBS_U2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <algorithm>\n",
        "#include <cassert>\n",
        "#include <iostream>\n",
        "#include <vector\n",
        "#define size 1024\n",
        "\n",
        "__global__ void matrix_mul(int *a,int *b,int *c,int N)\n",
        "{\n",
        "    int\n",
        "}\n"
      ],
      "metadata": {
        "id": "uNsge1knFgqC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ca56856-2638-4303-c210-e4bf76549024"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome To GeeksforGeeks\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
        "\n",
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BX0x3e5PO6pV",
        "outputId": "f2af986b-7101-44e2-f3aa-d0b0ee3533d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-m6sui261\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-m6sui261\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 0d2ab99cccbbc682722e708515fe9c4cfc50185a\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "The nvcc_plugin extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc_plugin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "\n",
        "__global__ void mat_naive(int* a,int*b,int *c,int n)\n",
        "{\n",
        "    int row = blockIdx.y*n + threadIdx.x;\n",
        "    int col= blockIndx.x*n + threadIdx.y;\n",
        "   int sum=0;\n",
        "    if(row<n && col<n)\n",
        "    {\n",
        "     for(int i=0;i<n;i++)\n",
        "     {\n",
        "         sum+= a[row*n+i]*b[i*n+col];\n",
        "     }\n",
        "\n",
        "    }\n",
        "    c[row*n+col]=sum;\n",
        "}\n",
        "int main()\n",
        "{\n",
        "    int n=1024;\n",
        "    size_t bytes=sizeof(int)*n*n;\n",
        "\n",
        "    std::vector<int> a;\n",
        "    a.reserve(N);\n",
        "    std::vector<int> b;\n",
        "    b.reserve(N);\n",
        "    std::vector<int> c;\n",
        "    c.reserve(N);\n",
        "\n",
        "\n",
        "    for(int i=0;i<n;i++)\n",
        "    {\n",
        "        a.push_back(rand()%100);\n",
        "        b.push_back(rand()%100);\n",
        "    }\n",
        "\n",
        "    int *d_a,*d_b,*d_c;\n",
        "    cudaMalloc(&d_a,bytes);\n",
        "    cudaMalloc(&d_b,bytes);\n",
        "    cudaMalloc(&d_c,bytes);\n",
        "\n",
        "    cudaMemcpy(d_a,a.data(),bytes,cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b,b.data(),bytes,cudaMemcpyHostToDevice);\n",
        "    int blocksize=16;\n",
        "    int blocksno= n/blocksize;\n",
        "  dim3 threads(blocksize,blocksize);\n",
        "  dim3 blocks(blocksno,blocksno);\n",
        "\n",
        "      mat_naive<<<blocks, threads>>>(d_a, d_b, d_c, n);\n",
        "\n",
        "    cudaMemcpy(h_c.data(), d_c, bytes, cudaMemcpyDeviceToHost);\n",
        "  cout << \"COMPLETED SUCCESSFULLY\\n\";\n",
        "\n",
        "  // Free memory on device\n",
        "  cudaFree(d_a);\n",
        "  cudaFree(d_b);\n",
        "  cudaFree(d_c);\n",
        "\n",
        "  return 0;\n",
        "\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "5xE1Q90HO_Y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
        "\n",
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iiimks86_WSz",
        "outputId": "769947c8-741a-444c-ac9c-cb59157fe905"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-_5_ynnzw\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-_5_ynnzw\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 0d2ab99cccbbc682722e708515fe9c4cfc50185a\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4716 sha256=0ae2f1297685226b1470671ab2a57664403521d714e36f21de06953a85bf222e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-z2ya9i7w/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n",
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <algorithm>\n",
        "#include <cassert>\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "\n",
        "__global__ void mat_naive(int* a, int* b, int* c, int n) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (row < n && col < n) {\n",
        "        int sum = 0;\n",
        "        for (int i = 0; i < n; i++) {\n",
        "            sum += a[row * n + i] * b[i * n + col];\n",
        "        }\n",
        "        c[row * n + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "void verify_result(std::vector<int>& a, std::vector<int>& b,  std::vector<int>& c, int n) {\n",
        "    // For every row...\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        // For every column...\n",
        "        for (int j = 0; j < n; j++) {\n",
        "            // For every element in the row-column pair\n",
        "            int tmp = 0;\n",
        "            for (int k = 0; k < n; k++) {\n",
        "                // Accumulate the partial results\n",
        "                tmp += a[i * n + k] * b[k * n + j];\n",
        "            }\n",
        "\n",
        "            // Check against the GPU result\n",
        "            assert(tmp == c[i * n + j]);\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int n = 1024;\n",
        "    size_t bytes = sizeof(int) * n * n;\n",
        "\n",
        "    std::vector<int> a;\n",
        "    a.reserve(n * n);\n",
        "    std::vector<int> b;\n",
        "    b.reserve(n * n);\n",
        "    std::vector<int> c;\n",
        "    c.reserve(n * n);\n",
        "\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        a.push_back(rand() % 100);\n",
        "        b.push_back(rand() % 100);\n",
        "    }\n",
        "\n",
        "    int* d_a, *d_b, *d_c;\n",
        "    cudaMalloc(&d_a, bytes);\n",
        "    cudaMalloc(&d_b, bytes);\n",
        "    cudaMalloc(&d_c, bytes);\n",
        "\n",
        "    cudaMemcpy(d_a, a.data(), bytes, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, b.data(), bytes, cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 threads(16, 16);\n",
        "    dim3 blocks((n + threads.x - 1) / threads.x, (n + threads.y - 1) / threads.y);\n",
        "\n",
        "    mat_naive<<<blocks, threads>>>(d_a, d_b, d_c, n);\n",
        "\n",
        "    cudaMemcpy(c.data(), d_c, bytes, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    verify_result(a, b, c, n);\n",
        "\n",
        "    std::cout << \"COMPLETED SUCCESSFULLY\\n\";\n",
        "\n",
        "    // Free memory on device\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRQ9Gwze_ghz",
        "outputId": "38ee29a8-30d8-4f21-d257-b4696f76f864"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMPLETED SUCCESSFULLY\n",
            "\n"
          ]
        }
      ]
    }
  ]
}